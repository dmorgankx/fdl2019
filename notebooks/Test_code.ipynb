{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\l ml/ml.q\n",
    ".ml.loadfile`:init.q\n",
    ".ml.loadfile`:clust/init.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\l ../automl/automl.q\n",
    ".aml.loadfile`:init.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "avs:.p.import[`sklearn.metrics]`:average_precision_score\n",
    "svc:.p.import[`sklearn.svm]`:SVC\n",
    "array:.p.import[`numpy]`:array\n",
    "mattab:{flip value flip x}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Why the choice to standardize to 7 characters to 8 and ignore the rest, there are some sites with 9 ... 15 etc\n",
    "* Some duplicate sites exist with the same latitude and longitude but different site number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ldfn:{(\"S\",(5#\"F\"),\"SFFSFSFFFFSFSSFSSFFFSFFSFF\";enlist \",\")0:`$\":data/snap_sampled_imp_nlcd_20\",x,\".csv\"}\n",
    "conv7_fn:{`$$[7=count x;\"0\",;]x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basin:(\"S\",242#\"F\";enlist \",\")0:`:data/gages_with_basin_attr.csv\n",
    "gauges:(\"SSSSFFSSIFFFFFFFFSSISSSSFF\";enlist \",\")0:`:data/usgs_gage_subset.csv\n",
    "nlcd06:ldfn\"06\";nlcd11:ldfn\"11\";nlcd16:ldfn\"16\" \n",
    "warnings:.ml.df2tab .p.import[`geopandas;`:read_file]\"data/national_shapefile_obs.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\\l gagesdir/gagesdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no  date    height dec_lat_va dec_long_v\n",
      "---------------------------------------------\n",
      "01200000 2009.07 3.8    41.65876   -73.52868 \n",
      "01200000 2009.08 1.82   41.65876   -73.52868 \n",
      "01200000 2009.09 1.29   41.65876   -73.52868 \n",
      "01200000 2009.10 2.04   41.65876   -73.52868 \n",
      "01200000 2009.11 1.71   41.65876   -73.52868 \n",
      "01200000 2009.12 4.17   41.65876   -73.52868 \n",
      "01200000 2010.01 2.8    41.65876   -73.52868 \n",
      "01200000 2010.02 4.35   41.65876   -73.52868 \n",
      "01200000 2010.03 6.17   41.65876   -73.52868 \n",
      "01200000 2010.04 1.96   41.65876   -73.52868 \n",
      "01200000 2010.05 1.22   41.65876   -73.52868 \n",
      "01200000 2010.06 0.91   41.65876   -73.52868 \n",
      "01200000 2010.07 0.76   41.65876   -73.52868 \n",
      "01200000 2010.08 0.83   41.65876   -73.52868 \n",
      "01200000 2010.09 1.5    41.65876   -73.52868 \n",
      "01200000 2010.10 1.63   41.65876   -73.52868 \n",
      "01200000 2010.11 1.8    41.65876   -73.52868 \n",
      "01200000 2010.12 2.05   41.65876   -73.52868 \n",
      "01200000 2011.01 2.15   41.65876   -73.52868 \n",
      "01200000 2011.02 3.75   41.65876   -73.52868 \n",
      "..\n"
     ]
    }
   ],
   "source": [
    "maxht:0!select max height by`$site_no,date from str\n",
    "maxht:0!select by site_no,\"m\"$date from delete from maxht where height<0\n",
    "gauges:update conv7_fn each string each site_no from gauges\n",
    "show httab:maxht ij 1!select site_no,dec_lat_va,dec_long_v from gauges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no  long     lat     elv  date       ppt \n",
      "----------------------------------------------\n",
      "01367690 -74.5596 41.1053 1056 2019.01.01 0.94\n",
      "01367690 -74.5596 41.1053 1056 2019.01.02 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.03 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.04 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.05 0.38\n",
      "01367690 -74.5596 41.1053 1056 2019.01.06 0.79\n",
      "01367690 -74.5596 41.1053 1056 2019.01.07 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.08 0.02\n",
      "01367690 -74.5596 41.1053 1056 2019.01.09 0.15\n",
      "01367690 -74.5596 41.1053 1056 2019.01.10 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.11 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.12 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.13 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.14 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.15 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.16 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.17 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.18 0.06\n",
      "01367690 -74.5596 41.1053 1056 2019.01.19 0   \n",
      "01367690 -74.5596 41.1053 1056 2019.01.20 1.02\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "fp:hsym`$dir,/:string key`$dir:\":../../data/prism/\"\n",
    "precipall:raze{`site_no`long`lat`elv`date`ppt xcol 10_(\"SFFFDF\";enlist \",\")0:x}each fp\n",
    "show precipall:update conv7_fn each string each site_no from precipall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds:distinct gauges`site_no\n",
    "rms:asc ds where 12<count each string each ds\n",
    "names:0!select i by site_no from precipall where site_no in `$12#'string each rms\n",
    "matchnames:0!select i by lat,long from precipall where i in names[`x][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1:til[26]except 21 22\n",
    "lst2:til[25]except 20\n",
    "i1:rms[lst1],rms[21 22]\n",
    "i2:(names[`x]lst2),matchnames`x\n",
    "precipall:{![x;enlist(in;`i;z);0b;enlist[`site_no]!enlist enlist y]}/[precipall;i1;i2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "precipall:update\"m\"$date from precipall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deanna/anaconda3/lib/python3.6/site-packages/statsmodels/regression/linear_model.py:846: RuntimeWarning: divide by zero encountered in log\n",
      "  llf = -nobs2*np.log(2*np.pi) - nobs2*np.log(ssr / nobs) - nobs2\n",
      "/home/deanna/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:1100: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return self.params / self.bse\n"
     ]
    }
   ],
   "source": [
    "fn2use:update valid:0b from .ml.fresh.params where pnum>0\n",
    "cfeats:.ml.fresh.createfeatures[precipall;`site_no`date;`ppt;fn2use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainmonth:1_0!cfeats,'select first distinct lat,first distinct long,elevation:distinct elv by site_no,date from precipall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no  date    ppt_absenergy ppt_abssumchange ppt_count ppt_countabovemean ..\n",
      "-----------------------------------------------------------------------------..\n",
      "01200000 2009.07 8.3659        11.36            31        10                 ..\n",
      "01200000 2009.08 5.0394        7.11             31        9                  ..\n",
      "01200000 2009.09 0.8817        2.46             30        4                  ..\n",
      "01200000 2009.10 3.7711        8                31        8                  ..\n",
      "01200000 2009.11 0.4824        1.94             30        6                  ..\n",
      "01200000 2009.12 3.7491        6.75             31        9                  ..\n",
      "01200000 2010.01 3.2776        5.01             31        5                  ..\n",
      "01200000 2010.02 6.1295        5.87             28        5                  ..\n",
      "01200000 2010.03 6.6804        6.84             31        6                  ..\n",
      "01200000 2010.04 0.7151        2.46             30        8                  ..\n",
      "01200000 2010.05 0.6951        2.84             31        8                  ..\n",
      "01200000 2010.06 1.3336        4.72             30        7                  ..\n",
      "01200000 2010.07 0.9515        3.98             31        7                  ..\n",
      "01200000 2010.08 9.0431        10.22            31        5                  ..\n",
      "01200000 2010.09 1.0385        2.5              30        5                  ..\n",
      "01200000 2010.10 18.2534       7.48             31        7                  ..\n",
      "01200000 2010.11 2.5415        5.42             30        6                  ..\n",
      "01200000 2010.12 6.6532        8.27             31        4                  ..\n",
      "01200000 2011.01 1.5309        4.5              31        9                  ..\n",
      "01200000 2011.02 2.0207        4.32             28        8                  ..\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "ansf:{where 0<>count each ss[;y]each string each cols x}\n",
    "constcols:cb til[count cb:cols basin]except raze ansf[basin]each(\"2009\";\"2010\";\"2011\")\n",
    "basinupd:flip constcols!basin constcols\n",
    "show joinedtab:rainmonth ij`site_no xkey basinupd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list:`site_no`INTPTLAT`INTPTLON`Measure`REACHCODE`distance`imp\n",
    "sym_list:`SOURCE_FEA`INTPTLAT`INTPTLON`Measure`REACHCODE`distance\n",
    "imp_list:`imp_nlcd_2006`imp_nlcd_2011`imp_nlcd_2016\n",
    "tab_list:(nlcd06;nlcd11;nlcd16)\n",
    "nl_tab:raze{[x;y;z;r]?[r;();0b;x!y,z]}[col_list;sym_list]'[imp_list;tab_list]\n",
    "nl_tab:1!update site_no:conv7_fn each string each site_no from nl_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no  date    ppt_absenergy ppt_abssumchange ppt_count ppt_countabovemean ..\n",
      "-----------------------------------------------------------------------------..\n",
      "01200000 2009.07 8.3659        11.36            31        10                 ..\n",
      "01200000 2009.08 5.0394        7.11             31        9                  ..\n",
      "01200000 2009.09 0.8817        2.46             30        4                  ..\n",
      "01200000 2009.10 3.7711        8                31        8                  ..\n",
      "01200000 2009.11 0.4824        1.94             30        6                  ..\n",
      "01200000 2009.12 3.7491        6.75             31        9                  ..\n",
      "01200000 2010.01 3.2776        5.01             31        5                  ..\n",
      "01200000 2010.02 6.1295        5.87             28        5                  ..\n",
      "01200000 2010.03 6.6804        6.84             31        6                  ..\n",
      "01200000 2010.04 0.7151        2.46             30        8                  ..\n",
      "01200000 2010.05 0.6951        2.84             31        8                  ..\n",
      "01200000 2010.06 1.3336        4.72             30        7                  ..\n",
      "01200000 2010.07 0.9515        3.98             31        7                  ..\n",
      "01200000 2010.08 9.0431        10.22            31        5                  ..\n",
      "01200000 2010.09 1.0385        2.5              30        5                  ..\n",
      "01200000 2010.10 18.2534       7.48             31        7                  ..\n",
      "01200000 2010.11 2.5415        5.42             30        6                  ..\n",
      "01200000 2010.12 6.6532        8.27             31        4                  ..\n",
      "01200000 2011.01 1.5309        4.5              31        9                  ..\n",
      "01200000 2011.02 2.0207        4.32             28        8                  ..\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show newjoinedtab:(update year:{$[x<2011;6;x<2016;11;16]}each`year$date from joinedtab)ij nl_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_ind:{first z _asc?[x;();y;`i]}[`warnings]\n",
    "delac:del_ind[`Action;0]\n",
    "delmj:del_ind[`Major;1]\n",
    "delmd:del_ind[`Moderate;2]\n",
    "delfl:del_ind[`Flood;2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_idx:distinct delac,delmj,delmd,delfl\n",
    "wrn:select from warnings where not i in del_idx\n",
    "warning:update nn:i from wrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlatl:gauges[`dec_lat_va`dec_long_v],'`float$'warning`Latitude`Longitude\n",
    "tabw:.ml.clust.kd.buildtree[wlatl;2]\n",
    "gauge_val:count[warning]+til count gauges\n",
    "nnwarn:.ml.clust.kd.i.nns[;tabw;(count[warning]#0),count[gauges]#1;flip wlatl;`edist]each gauge_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "joins:([site_no:gauges`site_no]nn:nnwarn[;0];ndw:nnwarn[;1])\n",
    "floodlvl:(maxht ij joins)lj`nn xkey warning\n",
    "floodlvl[`Action`Moderate`Flood`Major]:\"F\"$'floodlvl[`Action`Moderate`Flood`Major]\n",
    "floodlvl:update conv7_fn each string each site_no from floodlvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no  date    Action Flood Moderate Major no_Action no_Flood no_Mod no_Major\n",
      "-------------------------------------------------------------------------------\n",
      "01200000 2009.07 17     19    22       24    0         0        0      0       \n",
      "01200000 2009.08 17     19    22       24    0         0        0      0       \n",
      "01200000 2009.09 17     19    22       24    0         0        0      0       \n",
      "01200000 2009.10 17     19    22       24    0         0        0      0       \n",
      "01200000 2009.11 17     19    22       24    0         0        0      0       \n",
      "01200000 2009.12 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.01 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.02 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.03 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.04 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.05 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.06 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.07 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.08 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.09 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.10 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.11 17     19    22       24    0         0        0      0       \n",
      "01200000 2010.12 17     19    22       24    0         0        0      0       \n",
      "01200000 2011.01 17     19    22       24    0         0        0      0       \n",
      "01200000 2011.02 17     19    22       24    0         0        0      0       \n",
      "..\n"
     ]
    }
   ],
   "source": [
    "show 0!target:select distinct Action,distinct Flood,distinct Moderate,distinct Major,\n",
    "       no_Action:count where height>Action,no_Flood:count where height>Flood,\n",
    "       no_Mod:count where height>Moderate,no_Major:count where height>Major \n",
    "       by site_no,\"m\"$date \n",
    "       from floodlvl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "allmerged:newjoinedtab ij `site_no`date xkey target\n",
    "allmerged[`Action`Flood`Moderate`Major`elevation]:raze each allmerged[`Action`Flood`Moderate`Major`elevation]\n",
    "allmerged[`site_no] :\"F\"$string each allmerged[`site_no]\n",
    "allmerged[`lat`long]:raze each \"F\"$'string each allmerged[`lat`long]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi:acos -1\n",
    "allmerged:update month:`mm$date from allmerged\n",
    "allmerged:update cos_t:cos 2*pi*date%12,\n",
    "                 sin_t:sin 2*pi*date%12\n",
    "                 from allmerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "site_no date    ppt_absenergy ppt_abssumchange ppt_count ppt_countabovemean p..\n",
      "-----------------------------------------------------------------------------..\n",
      "1200000 2009.07 8.3659        11.36            31        10                 2..\n",
      "1302020 2009.07 2.898         7.66             31        12                 1..\n",
      "1303000 2009.07 2.8174        7.17             31        9                  2..\n",
      "1303500 2009.07 3.2061        7.6              31        8                  2..\n",
      "1304000 2009.07 7.5639        10.36            31        5                  2..\n",
      "1304500 2009.07 6.7083        9.36             31        9                  2..\n",
      "1305000 2009.07 9.9485        11.28            31        5                  2..\n",
      "1305500 2009.07                                                              ..\n",
      "1306460 2009.07 8.6007        11.2             31        5                  2..\n",
      "1308000 2009.07 4.8711        9.27             31        6                  2..\n",
      "1308500 2009.07 4.8711        9.27             31        6                  2..\n",
      "1309500 2009.07 4.0942        8.8              31        7                  2..\n",
      "1310500 2009.07                                                              ..\n",
      "1311500 2009.07 1.8739        6.4              31        10                 2..\n",
      "1312000 2009.07 2.0396        6.52             31        11                 2..\n",
      "1315000 2009.07 3.8949        7.1              31        5                  2..\n",
      "1315500 2009.07 3.9603        7.43             31        7                  2..\n",
      "1317000 2009.07 5.9315        9.93             31        9                  2..\n",
      "1318500 2009.07 9.0268        11.23            31        7                  2..\n",
      "1321000 2009.07 4.1141        7.71             31        9                  2..\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "/Join all dates within time range with stream sites so that there is no gaps in the time series\n",
    "// x=table; y=col1; z=col2\n",
    "\n",
    "ch_fn:{(count distinct x y)#'asc distinct x z}\n",
    "all_dt_range:([]site_no:raze flip ch_fn[allmerged;`date;`site_no];\n",
    "                date:raze ch_fn[allmerged;`site_no;`date])\n",
    "\n",
    "show all_dt_merge:all_dt_range lj 2!allmerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    ".ml.featurelag:{[x;c;l]\n",
    " if[(::)~c;c:.ml.i.fndcols[x;\"f\"]];\n",
    " v:raze{y xprev'x}[x c,:()]each l,:();\n",
    " max[l]_flip flip[x],(raze`$string[c],\\:/:\"_lag_\",/:string l)!v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ksll:key select by site_no,lat,long from all_dt_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lagfeats:{[x;y]t:select from y where site_no=x`site_no,lat=x`lat,long=x`long;\n",
    "          2!.ml.featurelag[t;(::);1 2 3 12]}\n",
    "allmerged:raze lagfeats[;all_dt_merge]each ksll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "/\n",
    "cols_fn   :{raze x[`cs]#'x y}\n",
    "feat_fns  :{raze {x xprev raze y}[z]each ?[x;();();y]}\n",
    "catch_tgts:0!select site_no,no_Flood,date,cs:count date by site_no from all_dt_merge\n",
    "\n",
    "lagy  :feat_fns[catch_tgts;`no_Flood;12]\n",
    "lag1  :feat_fns[catch_tgts;`no_Flood;1]\n",
    "lag2  :feat_fns[catch_tgts;`no_Flood;2]\n",
    "lag3  :feat_fns[catch_tgts;`no_Flood;3]\n",
    "lagall:raze{count[x]mavg raze x}each?[catch_tgts;();();`no_Flood]\n",
    "lagavg:avg each lag1,'lag2,'lag3\n",
    "\n",
    "lagdt:([]site_no:cols_fn[catch_tgts;`site_no];date:cols_fn[catch_tgts;`date];\n",
    "         lagged_target_1yr:ddlagy;lagged_target_recent:lag3;lagged_target_all:lagall)\n",
    "show lagdt:delete from lagdt where i in where any flip null value each lagdt\n",
    "\n",
    "catch_dts:0!select date,ppt_mean,ppt_max,ppt_var,cs:count i by site_no from all_dt_merge\n",
    "\n",
    "avg1:feat_fns[catch_dts;`ppt_mean;1]\n",
    "avg2:feat_fns[catch_dts;`ppt_mean;2]\n",
    "avg3:feat_fns[catch_dts;`ppt_mean;3]\n",
    "\n",
    "max1:feat_fns[catch_dts;`ppt_max;1]\n",
    "max2:feat_fns[catch_dts;`ppt_max;2]\n",
    "max3:feat_fns[catch_dts;`ppt_max;3]\n",
    "\n",
    "var1:feat_fns[catch_dts;`ppt_var;1]\n",
    "var2:feat_fns[catch_dts;`ppt_var;2]\n",
    "var3:feat_fns[catch_dts;`ppt_var;3]\n",
    "\n",
    "prevdt:([]site_no:raze cols_fn[catch_dts;`site_no];date:raze cols_fn[catch_dts;`date];\n",
    "          avg_prev_1:avg1;avg_prev_2:avg2;avg_prev_3:avg3;\n",
    "          max_prev_1:max1;max_prev_2:max2;max_prev_3:max3;\n",
    "          var_prev_1:var1;var_prev_2:var2;var_prev_3:var3)\n",
    "\n",
    "show prevdt:delete from prevdt where i in where any flip null value each prevdt\n",
    "\n",
    "catch_atts:0!select site_no,ppt_mean,ppt_max,ppt_var,\n",
    "             cs:count i by date,catch:2#'string each site_no \n",
    "             from all_dt_merge\n",
    "\n",
    "avg1:feat_fns[catch_atts;`ppt_mean;1]\n",
    "avg2:feat_fns[catch_atts;`ppt_mean;2]\n",
    "avg3:feat_fns[catch_atts;`ppt_mean;3]\n",
    "\n",
    "max1:feat_fns[catch_atts;`ppt_max;1]\n",
    "max2:feat_fns[catch_atts;`ppt_max;2]\n",
    "max3:feat_fns[catch_atts;`ppt_max;3]\n",
    "\n",
    "var1:feat_fns[catch_atts;`ppt_var;1]\n",
    "var2:feat_fns[catch_atts;`ppt_var;2]\n",
    "var3:feat_fns[catch_atts;`ppt_var;3]\n",
    "\n",
    "upstr:([]site_no:raze cols_fn[catch_dts;`site_no];date:raze cols_fn[catch_dts;`date];\n",
    "         avg_ups_1:avg1;avg_ups_2:avg2;avg_ups_3:avg3;\n",
    "         max_ups_1:max1;max_ups_2:max2;max_ups_3:max3;\n",
    "         var_ups_1:var1;var_ups_2:var2;var_ups_3:var3)\n",
    "\n",
    "show upstr:delete from upstr where i in where any flip null value each upstr\n",
    "\n",
    "show allmerged:((allmerged ij 2!upstr) ij 2!prevdt) ij 2!lagdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    ".aml.loadfile`:init.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y:0<exec no_Flood from allmerged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "alm:`site_no`date`lat`long xkey delete no_Action,no_Flood,no_Mod,no_Major from allmerged\n",
    "tabreduced:2!key[alm],'.aml.preproc[value alm;y;`normal;`scale_fn`cols2scale!(`.ml.stdscaler;cols value alm)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X:value tabreduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdls:.aml.models[`class;y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "d:`xv`prf`scf`k`seed!(`kfstrat;.ml.xv.fitpredict;`class`reg!(`.ml.accuracy;`.ml.mse);5;42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: AdaBoostClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deanna/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: RandomForestClassifier\n",
      "Running model: GradientBoostingClassifier\n",
      "Running model: LogisticRegression\n",
      "Running model: GaussianNB\n",
      "Running model: KNeighborsClassifier\n",
      "Running model: MLPClassifier\n",
      "Running model: SVC\n",
      "Running model: LinearSVC\n",
      "Running model: BinaryKeras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2019-08-02 07:11:32.375290: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-08-02 07:11:32.376629: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`AdaBoostClassifier`RandomForestClassifier`GradientBoostingClassifier`Logisti..\n"
     ]
    }
   ],
   "source": [
    "r:.aml.runmodels[flip value flip 0^X;y;mdls;d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm:mdls`model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mdl                        class     precision recall    f1_score  support\n",
       "--------------------------------------------------------------------------\n",
       "RandomForestClassifier     avg/total 0.9810524 0.938108  0.9584172 93541  \n",
       "MLPClassifier              avg/total 0.9643532 0.9495858 0.9568304 93541  \n",
       "GradientBoostingClassifier avg/total 0.9811285 0.9292758 0.9534924 93541  \n",
       "SVC                        avg/total 0.9808049 0.919768  0.9478941 93541  \n",
       "KNeighborsClassifier       avg/total 0.9645959 0.9171063 0.9393659 93541  \n",
       "LogisticRegression         avg/total 0.9314827 0.8734978 0.9000562 93541  \n",
       "BinaryKeras                avg/total 0.9083637 0.8788774 0.8929716 93541  \n",
       "AdaBoostClassifier         avg/total 0.9340033 0.8598219 0.8928841 93541  \n",
       "LinearSVC                  avg/total 0.8108545 0.8780894 0.8404459 93541  \n",
       "GaussianNB                 avg/total 0.552502  0.7015733 0.3828532 93541  \n"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "`f1_score xdesc{(enlist[`mdl]!enlist y),@[;2]0!.ml.classreport . raze each flip x}'[r;mm]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Q (kdb+)",
   "language": "q",
   "name": "qpk"
  },
  "language_info": {
   "file_extension": ".q",
   "mimetype": "text/x-q",
   "name": "q",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
